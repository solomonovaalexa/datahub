"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[82557],{7653:(e,t,n)=>{n.d(t,{A:()=>a});const a={icon:{tag:"svg",attrs:{"fill-rule":"evenodd",viewBox:"64 64 896 896",focusable:"false"},children:[{tag:"path",attrs:{d:"M512 64c247.4 0 448 200.6 448 448S759.4 960 512 960 64 759.4 64 512 264.6 64 512 64zm127.98 274.82h-.04l-.08.06L512 466.75 384.14 338.88c-.04-.05-.06-.06-.08-.06a.12.12 0 00-.07 0c-.03 0-.05.01-.09.05l-45.02 45.02a.2.2 0 00-.05.09.12.12 0 000 .07v.02a.27.27 0 00.06.06L466.75 512 338.88 639.86c-.05.04-.06.06-.06.08a.12.12 0 000 .07c0 .03.01.05.05.09l45.02 45.02a.2.2 0 00.09.05.12.12 0 00.07 0c.02 0 .04-.01.08-.05L512 557.25l127.86 127.87c.04.04.06.05.08.05a.12.12 0 00.07 0c.03 0 .05-.01.09-.05l45.02-45.02a.2.2 0 00.05-.09.12.12 0 000-.07v-.02a.27.27 0 00-.05-.06L557.25 512l127.87-127.86c.04-.04.05-.06.05-.08a.12.12 0 000-.07c0-.03-.01-.05-.05-.09l-45.02-45.02a.2.2 0 00-.09-.05.12.12 0 00-.07 0z"}}]},name:"close-circle",theme:"filled"}},4732:(e,t,n)=>{n.d(t,{A:()=>c});var a=n(89379),i=n(96540),o=n(7653),r=n(38046),s=function(e,t){return i.createElement(r.A,(0,a.A)((0,a.A)({},e),{},{ref:t,icon:o.A}))};const c=i.forwardRef(s)},43655:(e,t,n)=>{n.d(t,{A:()=>b});var a=n(96540),i=n(20053);const o="availabilityCard_P5od",r="managedIcon_AxXO",s="platform_wqXv",c="platformAvailable_Y8lN";var u=n(4732),l=n(89379);const g={icon:{tag:"svg",attrs:{viewBox:"64 64 896 896",focusable:"false"},children:[{tag:"path",attrs:{d:"M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64zm193.5 301.7l-210.6 292a31.8 31.8 0 01-51.7 0L318.5 484.9c-3.8-5.3 0-12.7 6.5-12.7h46.9c10.2 0 19.9 4.9 25.9 13.3l71.2 98.8 157.2-218c6-8.3 15.6-13.3 25.9-13.3H699c6.5 0 10.3 7.4 6.5 12.7z"}}]},name:"check-circle",theme:"filled"};var p=n(38046),d=function(e,t){return a.createElement(p.A,(0,l.A)((0,l.A)({},e),{},{ref:t,icon:g}))};const h=a.forwardRef(d);const m={icon:{tag:"svg",attrs:{viewBox:"64 64 896 896",focusable:"false"},children:[{tag:"path",attrs:{d:"M811.4 418.7C765.6 297.9 648.9 212 512.2 212S258.8 297.8 213 418.6C127.3 441.1 64 519.1 64 612c0 110.5 89.5 200 199.9 200h496.2C870.5 812 960 722.5 960 612c0-92.7-63.1-170.7-148.6-193.3zm36.3 281a123.07 123.07 0 01-87.6 36.3H263.9c-33.1 0-64.2-12.9-87.6-36.3A123.3 123.3 0 01140 612c0-28 9.1-54.3 26.2-76.3a125.7 125.7 0 0166.1-43.7l37.9-9.9 13.9-36.6c8.6-22.8 20.6-44.1 35.7-63.4a245.6 245.6 0 0152.4-49.9c41.1-28.9 89.5-44.2 140-44.2s98.9 15.3 140 44.2c19.9 14 37.5 30.8 52.4 49.9 15.1 19.3 27.1 40.7 35.7 63.4l13.8 36.5 37.8 10c54.3 14.5 92.1 63.8 92.1 120 0 33.1-12.9 64.3-36.3 87.7z"}}]},name:"cloud",theme:"outlined"};var y=function(e,t){return a.createElement(p.A,(0,l.A)((0,l.A)({},e),{},{ref:t,icon:m}))};const f=a.forwardRef(y),b=({saasOnly:e,ossOnly:t})=>a.createElement("div",{className:(0,i.A)(o,"card")},a.createElement("strong",null,"Feature Availability"),a.createElement("div",null,a.createElement("span",{className:(0,i.A)(s,!e&&c)},"Self-Hosted DataHub ",e?a.createElement(u.A,null):a.createElement(h,null))),a.createElement("div",null,a.createElement(f,{className:r}),a.createElement("span",{className:(0,i.A)(s,!t&&c)},"DataHub Cloud ",t?a.createElement(u.A,null):a.createElement(h,null))))},49321:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>g,default:()=>f,frontMatter:()=>l,metadata:()=>p,toc:()=>h});n(96540);var a=n(15680),i=n(43655),o=n(53720),r=n(5400);function s(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function c(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))})),e}function u(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}const l={title:"Ingestion",slug:"/ui-ingestion",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/ui-ingestion.md"},g="Ingestion",p={unversionedId:"docs/ui-ingestion",id:"docs/ui-ingestion",title:"Ingestion",description:"Introduction",source:"@site/genDocs/docs/ui-ingestion.md",sourceDirName:"docs",slug:"/ui-ingestion",permalink:"/docs/ui-ingestion",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/ui-ingestion.md",tags:[],version:"current",frontMatter:{title:"Ingestion",slug:"/ui-ingestion",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/ui-ingestion.md"},sidebar:"overviewSidebar",previous:{title:"Incidents",permalink:"/docs/incidents/incidents"},next:{title:"Lineage",permalink:"/docs/generated/lineage/lineage-feature-guide"}},d={},h=[{value:"Introduction",id:"introduction",level:2},{value:"Running Metadata Ingestion",id:"running-metadata-ingestion",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Creating an Ingestion Source",id:"creating-an-ingestion-source",level:3},{value:"Step 1: Select a Platform Template",id:"step-1-select-a-platform-template",level:4},{value:"Step 2: Configure a Recipe",id:"step-2-configure-a-recipe",level:4},{value:"Creating a Secret",id:"creating-a-secret",level:5},{value:"Referencing a Secret",id:"referencing-a-secret",level:5},{value:"Step 3: Schedule Execution",id:"step-3-schedule-execution",level:4},{value:"Step 4: Finishing Up",id:"step-4-finishing-up",level:4},{value:"Advanced ingestion configs:",id:"advanced-ingestion-configs",level:5},{value:"Running an Ingestion Source",id:"running-an-ingestion-source",level:3},{value:"Cancelling an Ingestion Run",id:"cancelling-an-ingestion-run",level:3},{value:"Debugging a Failed Ingestion Run",id:"debugging-a-failed-ingestion-run",level:3},{value:"FAQ",id:"faq",level:2},{value:"I tried to ingest metadata after running &#39;datahub docker quickstart&#39;, but ingestion is failing with &#39;Failed to Connect&#39; errors. What do I do?",id:"i-tried-to-ingest-metadata-after-running-datahub-docker-quickstart-but-ingestion-is-failing-with-failed-to-connect-errors-what-do-i-do",level:3},{value:"I see &#39;N/A&#39; when I try to run ingestion. What do I do?",id:"i-see-na-when-i-try-to-run-ingestion-what-do-i-do",level:3},{value:"When should I NOT use UI Ingestion?",id:"when-should-i-not-use-ui-ingestion",level:3},{value:"How do I attach policies to the actions pod to give it permissions to pull metadata from various sources?",id:"how-do-i-attach-policies-to-the-actions-pod-to-give-it-permissions-to-pull-metadata-from-various-sources",level:3},{value:"Demo",id:"demo",level:2},{value:"Feedback / Questions / Concerns",id:"feedback--questions--concerns",level:2}],m={toc:h},y="wrapper";function f(e){var{components:t}=e,n=u(e,["components"]);return(0,a.yg)(y,c(function(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{},a=Object.keys(n);"function"==typeof Object.getOwnPropertySymbols&&(a=a.concat(Object.getOwnPropertySymbols(n).filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable})))),a.forEach((function(t){s(e,t,n[t])}))}return e}({},m,n),{components:t,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"ingestion"},"Ingestion"),(0,a.yg)(i.A,{mdxType:"FeatureAvailability"}),(0,a.yg)("h2",{id:"introduction"},"Introduction"),(0,a.yg)("p",null,"Starting in version ",(0,a.yg)("inlineCode",{parentName:"p"},"0.8.25"),", DataHub supports creating, configuring, scheduling, & executing batch metadata ingestion using the DataHub user interface. This makes\ngetting metadata into DataHub easier by minimizing the overhead required to operate custom integration pipelines. "),(0,a.yg)("p",null,"This document will describe the steps required to configure, schedule, and execute metadata ingestion inside the UI. "),(0,a.yg)("h2",{id:"running-metadata-ingestion"},"Running Metadata Ingestion"),(0,a.yg)("h3",{id:"prerequisites"},"Prerequisites"),(0,a.yg)("p",null,"To view & manage UI-based metadata ingestion, you must have the ",(0,a.yg)("inlineCode",{parentName:"p"},"Manage Metadata Ingestion")," & ",(0,a.yg)("inlineCode",{parentName:"p"},"Manage Secrets"),"\nprivileges assigned to your account. These can be granted by a ",(0,a.yg)("a",{parentName:"p",href:"/docs/authorization/policies"},"Platform Policy"),"."),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/ingestion-privileges.png"})),(0,a.yg)("p",null,"Once you have these privileges, you can begin to manage ingestion by navigating to the 'Ingestion' tab in DataHub. "),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/ingestion-tab.png"})),(0,a.yg)("p",null,"On this page, you'll see a list of active ",(0,a.yg)("strong",{parentName:"p"},"Ingestion Sources"),". An Ingestion Sources is a unique source of metadata ingested\ninto DataHub from an external source like Snowflake, Redshift, or BigQuery."),(0,a.yg)("p",null,"If you're just getting started, you won't have any sources. In the following sections, we'll describe how to create\nyour first ",(0,a.yg)("strong",{parentName:"p"},"Ingestion Source"),". "),(0,a.yg)("h3",{id:"creating-an-ingestion-source"},"Creating an Ingestion Source"),(0,a.yg)(o.A,{mdxType:"Tabs"},(0,a.yg)(r.A,{value:"ui",label:"UI",default:!0,mdxType:"TabItem"},(0,a.yg)("p",null,"Before ingesting any metadata, you need to create a new Ingestion Source. Start by clicking ",(0,a.yg)("strong",{parentName:"p"},"+ Create new source"),"."),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/create-new-ingestion-source-button.png"})),(0,a.yg)("h4",{id:"step-1-select-a-platform-template"},"Step 1: Select a Platform Template"),(0,a.yg)("p",null,"In the first step, select a ",(0,a.yg)("strong",{parentName:"p"},"Recipe Template")," corresponding to the source type that you'd like to extract metadata from. Choose among\na variety of natively supported integrations, from Snowflake to Postgres to Kafka.\nSelect ",(0,a.yg)("inlineCode",{parentName:"p"},"Custom")," to construct an ingestion recipe from scratch. "),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/select-platform-template.png"})),(0,a.yg)("p",null,"Next, you'll configure an ingestion ",(0,a.yg)("strong",{parentName:"p"},"Recipe"),", which defines ",(0,a.yg)("em",{parentName:"p"},"how")," and ",(0,a.yg)("em",{parentName:"p"},"what")," to extract from the source system."),(0,a.yg)("h4",{id:"step-2-configure-a-recipe"},"Step 2: Configure a Recipe"),(0,a.yg)("p",null,"Next, you'll define an ingestion ",(0,a.yg)("strong",{parentName:"p"},"Recipe")," in ",(0,a.yg)("a",{parentName:"p",href:"https://yaml.org/"},"YAML"),". A ",(0,a.yg)("a",{parentName:"p",href:"/docs/metadata-ingestion/#recipes"},"Recipe")," is a set of configurations which is\nused by DataHub to extract metadata from a 3rd party system. It most often consists of the following parts:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},"A source ",(0,a.yg)("strong",{parentName:"li"},"type"),": The type of system you'd like to extract metadata from (e.g. snowflake, mysql, postgres). If you've chosen a native template, this will already be populated for you.\nTo view a full list of currently supported ",(0,a.yg)("strong",{parentName:"li"},"types"),", check out ",(0,a.yg)("a",{parentName:"li",href:"/docs/metadata-ingestion/#installing-plugins"},"this list"),".")),(0,a.yg)("ol",{start:2},(0,a.yg)("li",{parentName:"ol"},"A source ",(0,a.yg)("strong",{parentName:"li"},"config"),": A set of configurations specific to the source ",(0,a.yg)("strong",{parentName:"li"},"type"),". Most sources support the following types of configuration values: ",(0,a.yg)("ul",{parentName:"li"},(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Coordinates"),": The location of the system you want to extract metadata from"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Credentials"),": Authorized credentials for accessing the system you want to extract metadata from"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("strong",{parentName:"li"},"Customizations"),": Customizations regarding the metadata that will be extracted, e.g. which databases or tables to scan in a relational DB")))),(0,a.yg)("ol",{start:3},(0,a.yg)("li",{parentName:"ol"},"A sink ",(0,a.yg)("strong",{parentName:"li"},"type"),": A type of sink to route the metadata extracted from the source type. The officially supported DataHub sink\ntypes are ",(0,a.yg)("inlineCode",{parentName:"li"},"datahub-rest")," and ",(0,a.yg)("inlineCode",{parentName:"li"},"datahub-kafka"),". ")),(0,a.yg)("ol",{start:4},(0,a.yg)("li",{parentName:"ol"},"A sink ",(0,a.yg)("strong",{parentName:"li"},"config"),": Configuration required to send metadata to the provided sink type. For example, DataHub coordinates and credentials.")),(0,a.yg)("p",null,"A sample of a full recipe configured to ingest metadata from MySQL can be found in the image below."),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/example-mysql-recipe.png"})),(0,a.yg)("p",null,"Detailed configuration examples & documentation for each source type can be found on the ",(0,a.yg)("a",{parentName:"p",href:"/docs/metadata-ingestion/"},"DataHub Docs")," website."),(0,a.yg)("h5",{id:"creating-a-secret"},"Creating a Secret"),(0,a.yg)("p",null,"For production use cases, sensitive configuration values, such as database usernames and passwords,\nshould be hidden from plain view within your ingestion recipe. To accomplish this, you can create & embed ",(0,a.yg)("strong",{parentName:"p"},"Secrets"),". Secrets are named values\nthat are encrypted and stored within DataHub's storage layer."),(0,a.yg)("p",null,"To create a secret, first navigate to the 'Secrets' tab. Then click ",(0,a.yg)("inlineCode",{parentName:"p"},"+ Create new secret"),". "),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/create-secret.png"})),(0,a.yg)("p",null,(0,a.yg)("em",{parentName:"p"},"Creating a Secret to store the username for a MySQL database")),(0,a.yg)("p",null,"Inside the form, provide a unique name for the secret along with the value to be encrypted, and an optional description. Click ",(0,a.yg)("strong",{parentName:"p"},"Create")," when you are done.\nThis will create a Secret which can be referenced inside your ingestion recipe using its name. "),(0,a.yg)("h5",{id:"referencing-a-secret"},"Referencing a Secret"),(0,a.yg)("p",null,"Once a Secret has been created, it can be referenced from within your ",(0,a.yg)("strong",{parentName:"p"},"Recipe")," using variable substitution. For example,\nto substitute secrets for a MySQL username and password into a Recipe, your Recipe would be defined as follows:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-yaml"},"source:\n    type: mysql\n    config:\n        host_port: 'localhost:3306'\n        database: my_db\n        username: ${MYSQL_USERNAME}\n        password: ${MYSQL_PASSWORD}\n        include_tables: true\n        include_views: true\n        profiling:\n            enabled: true\nsink:\n    type: datahub-rest\n    config:\n        server: 'http://datahub-gms:8080'\n")),(0,a.yg)("p",null,(0,a.yg)("em",{parentName:"p"},"Referencing DataHub Secrets from a Recipe definition")),(0,a.yg)("p",null,"When the Ingestion Source with this Recipe executes, DataHub will attempt to 'resolve' Secrets found within the YAML. If a secret can be resolved, the reference is substituted for its decrypted value prior to execution.\nSecret values are not persisted to disk beyond execution time, and are never transmitted outside DataHub."),(0,a.yg)("blockquote",null,(0,a.yg)("p",{parentName:"blockquote"},(0,a.yg)("strong",{parentName:"p"},"Attention"),": Any DataHub users who have been granted the ",(0,a.yg)("inlineCode",{parentName:"p"},"Manage Secrets")," ",(0,a.yg)("a",{parentName:"p",href:"/docs/authorization/policies"},"Platform Privilege")," will be able to retrieve plaintext secret values using the GraphQL API. ")),(0,a.yg)("h4",{id:"step-3-schedule-execution"},"Step 3: Schedule Execution"),(0,a.yg)("p",null,"Next, you can optionally configure a schedule on which to execute your new Ingestion Source. This enables to schedule metadata extraction on a monthly, weekly, daily, or hourly cadence depending on the needs of your organization.\nSchedules are defined using CRON format. "),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/schedule-ingestion.png"})),(0,a.yg)("p",null,(0,a.yg)("em",{parentName:"p"},"An Ingestion Source that is executed at 9:15am every day, Los Angeles time")),(0,a.yg)("p",null,"To learn more about the CRON scheduling format, check out the ",(0,a.yg)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Cron"},"Wikipedia")," overview."),(0,a.yg)("p",null,"If you plan to execute ingestion on an ad-hoc basis, you can click ",(0,a.yg)("strong",{parentName:"p"},"Skip")," to skip the scheduling step entirely. Don't worry -\nyou can always come back and change this. "),(0,a.yg)("h4",{id:"step-4-finishing-up"},"Step 4: Finishing Up"),(0,a.yg)("p",null,"Finally, give your Ingestion Source a name. "),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/name-ingestion-source.png"})),(0,a.yg)("p",null,"Once you're happy with your configurations, click 'Done' to save your changes."),(0,a.yg)("h5",{id:"advanced-ingestion-configs"},"Advanced ingestion configs:"),(0,a.yg)("p",null,"DataHub's Managed Ingestion UI comes pre-configured to use the latest version of the DataHub CLI (",(0,a.yg)("a",{parentName:"p",href:"https://pypi.org/project/acryl-datahub/"},"acryl-datahub"),") that is compatible\nwith the server. However, you can override the default package version using the 'Advanced' source configurations."),(0,a.yg)("p",null,"To do so, simply click 'Advanced', then change the 'CLI Version' text box to contain the exact version\nof the DataHub CLI you'd like to use."),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/custom-ingestion-cli-version.png"})),(0,a.yg)("p",null,(0,a.yg)("em",{parentName:"p"},"Pinning the CLI version to version ",(0,a.yg)("inlineCode",{parentName:"em"},"0.8.23.2"))),(0,a.yg)("p",null,"Other advanced options include specifying ",(0,a.yg)("strong",{parentName:"p"},"environment variables"),", ",(0,a.yg)("strong",{parentName:"p"},"DataHub plugins")," or ",(0,a.yg)("strong",{parentName:"p"},"python packages at runtime"),". "),(0,a.yg)("p",null,"Once you're happy with your changes, simply click 'Done' to save. ")),(0,a.yg)(r.A,{value:"cli",label:"CLI",default:!0,mdxType:"TabItem"},(0,a.yg)("p",null,"You can upload and even update recipes using the cli as mentioned in the ",(0,a.yg)("a",{parentName:"p",href:"/docs/cli#ingest-deploy"},"cli documentation for uploading ingestion recipes"),".\nAn example execution for a given ",(0,a.yg)("inlineCode",{parentName:"p"},"recipe.yaml")," file, would look something like:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-bash"},'datahub ingest deploy --name "My Test Ingestion Source" --schedule "5 * * * *" --time-zone "UTC" -c recipe.yaml\n')),(0,a.yg)("p",null,"This would create a new recipe with the name ",(0,a.yg)("inlineCode",{parentName:"p"},"My Test Ingestion Source"),". Note that to update an existing recipe, it's ",(0,a.yg)("inlineCode",{parentName:"p"},"urn")," id must be passed as a parameter.\nDataHub supports having multiple recipes with the same name so to distinguish them we use the urn for unique identification.")),(0,a.yg)(r.A,{value:"graphql",label:"GraphQL",default:!0,mdxType:"TabItem"},(0,a.yg)("p",null,"Create ingestion sources using ",(0,a.yg)("a",{parentName:"p",href:"/docs/api/graphql/overview"},"DataHub's GraphQL API")," using the ",(0,a.yg)("strong",{parentName:"p"},"createIngestionSource")," mutation endpoint."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-graphql"},'mutation {\n   createIngestionSource(input: {\n      name: "My Test Ingestion Source",\n      type: "mysql",\n      description: "My ingestion source description",\n      schedule: {interval: "*/5 * * * *", timezone: "UTC"},\n      config: {\n         recipe: "{\\"source\\":{\\"type\\":\\"mysql\\",\\"config\\":{\\"include_tables\\":true,\\"database\\":null,\\"password\\":\\"${MYSQL_PASSWORD}\\",\\"profiling\\":{\\"enabled\\":false},\\"host_port\\":null,\\"include_views\\":true,\\"username\\":\\"${MYSQL_USERNAME}\\"}},\\"pipeline_name\\":\\"urn:li:dataHubIngestionSource:f38bd060-4ea8-459c-8f24-a773286a2927\\"}",\n         version: "0.8.18",\n         executorId: "mytestexecutor",\n      }\n   })\n}\n')),(0,a.yg)("p",null,"To update sources, please use the ",(0,a.yg)("inlineCode",{parentName:"p"},"updateIngestionSource")," endpoint. It is almost identical to the create endpoint, only requiring the urn of the source to be updated in addition to the same input as the create endpoint."),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Note"),": Recipe must be double quotes escaped"))),(0,a.yg)("h3",{id:"running-an-ingestion-source"},"Running an Ingestion Source"),(0,a.yg)("p",null,"Once you've created your Ingestion Source, you can run it by clicking 'Execute'. Shortly after,\nyou should see the 'Last Status' column of the ingestion source change from ",(0,a.yg)("inlineCode",{parentName:"p"},"N/A")," to ",(0,a.yg)("inlineCode",{parentName:"p"},"Running"),". This\nmeans that the request to execute ingestion has been successfully picked up by the DataHub ingestion executor."),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/running-ingestion.png"})),(0,a.yg)("p",null,"If ingestion has executed successfully, you should see it's state shown in green as ",(0,a.yg)("inlineCode",{parentName:"p"},"Succeeded"),". "),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/successful-ingestion.png"})),(0,a.yg)("h3",{id:"cancelling-an-ingestion-run"},"Cancelling an Ingestion Run"),(0,a.yg)("p",null,"If your ingestion run is hanging, there may a bug in the ingestion source, or another persistent issue like exponential timeouts. If these situations,\nyou can cancel ingestion by clicking ",(0,a.yg)("strong",{parentName:"p"},"Cancel")," on the problematic run."),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/cancelled-ingestion.png"})),(0,a.yg)("p",null,"Once cancelled, you can view the output of the ingestion run by clicking ",(0,a.yg)("strong",{parentName:"p"},"Details"),". "),(0,a.yg)("h3",{id:"debugging-a-failed-ingestion-run"},"Debugging a Failed Ingestion Run"),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/failed-ingestion.png"})),(0,a.yg)("p",null,"A variety of things can cause an ingestion run to fail. Common reasons for failure include:  "),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Recipe Misconfiguration"),": A recipe has not provided the required or expected configurations for the ingestion source. You can refer\nto the ",(0,a.yg)("a",{parentName:"li",href:"/docs/metadata-ingestion"},"Metadata Ingestion Framework")," source docs to learn more about the configurations required for your source type."),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Failure to resolve Secrets"),": If DataHub is unable to find secrets that were referenced by your Recipe configuration, the ingestion run will fail.\nVerify that the names of the secrets referenced in your recipe match those which have been created. "),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Connectivity / Network Reachability"),": If DataHub is unable to reach a data source, for example due to DNS resolution\nfailures, metadata ingestion will fail. Ensure that the network where DataHub is deployed has access to the data source which\nyou are trying to reach. "),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("strong",{parentName:"li"},"Authentication"),": If you've enabled ",(0,a.yg)("a",{parentName:"li",href:"/docs/authentication/introducing-metadata-service-authentication"},"Metadata Service Authentication"),", you'll need to provide a Personal Access Token\nin your Recipe Configuration. To so this, set the 'token' field of the sink configuration to contain a Personal Access Token:")),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/ingestion-with-token.png"})),(0,a.yg)("p",null,"The output of each run is captured and available to view in the UI for easier debugging. To view output logs, click ",(0,a.yg)("strong",{parentName:"p"},"DETAILS"),"\non the corresponding ingestion run. "),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/ingestion-logs.png"})),(0,a.yg)("h2",{id:"faq"},"FAQ"),(0,a.yg)("h3",{id:"i-tried-to-ingest-metadata-after-running-datahub-docker-quickstart-but-ingestion-is-failing-with-failed-to-connect-errors-what-do-i-do"},"I tried to ingest metadata after running 'datahub docker quickstart', but ingestion is failing with 'Failed to Connect' errors. What do I do?"),(0,a.yg)("p",null,"If not due to one of the reasons outlined above, this may be because the executor running ingestion is unable\nto reach DataHub's backend using the default configurations. Try changing your ingestion recipe to make the ",(0,a.yg)("inlineCode",{parentName:"p"},"sink.config.server")," variable point to the Docker\nDNS name for the ",(0,a.yg)("inlineCode",{parentName:"p"},"datahub-gms")," pod: "),(0,a.yg)("p",{align:"center"},(0,a.yg)("img",{width:"70%",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/quickstart-ingestion-config.png"})),(0,a.yg)("h3",{id:"i-see-na-when-i-try-to-run-ingestion-what-do-i-do"},"I see 'N/A' when I try to run ingestion. What do I do?"),(0,a.yg)("p",null,"If you see 'N/A', and the ingestion run state never changes to 'Running', this may mean\nthat your executor (",(0,a.yg)("inlineCode",{parentName:"p"},"datahub-actions"),") container is down. "),(0,a.yg)("p",null,"This container is responsible for executing requests to run ingestion when they come in, either\non demand on a particular schedule. You can verify the health of the container using ",(0,a.yg)("inlineCode",{parentName:"p"},"docker ps"),". Moreover, you can inspect the container logs using by finding the container id\nfor the ",(0,a.yg)("inlineCode",{parentName:"p"},"datahub-actions")," container and running ",(0,a.yg)("inlineCode",{parentName:"p"},"docker logs <container-id>"),"."),(0,a.yg)("h3",{id:"when-should-i-not-use-ui-ingestion"},"When should I NOT use UI Ingestion?"),(0,a.yg)("p",null,"There are valid cases for ingesting metadata without the UI-based ingestion scheduler. For example,"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"You have written a custom ingestion Source"),(0,a.yg)("li",{parentName:"ul"},"Your data sources are not reachable on the network where DataHub is deployed. DataHub Cloud users can use a ",(0,a.yg)("a",{parentName:"li",href:"/docs/managed-datahub/operator-guide/setting-up-remote-ingestion-executor"},"remote executor")," for remote UI-based ingestion."),(0,a.yg)("li",{parentName:"ul"},"Your ingestion source requires context from a local filesystem (e.g. input files)"),(0,a.yg)("li",{parentName:"ul"},"You want to distribute metadata ingestion among multiple producers / environments")),(0,a.yg)("h3",{id:"how-do-i-attach-policies-to-the-actions-pod-to-give-it-permissions-to-pull-metadata-from-various-sources"},"How do I attach policies to the actions pod to give it permissions to pull metadata from various sources?"),(0,a.yg)("p",null,"This varies across the underlying platform. For AWS, please refer to this ",(0,a.yg)("a",{parentName:"p",href:"/docs/deploy/aws#iam-policies-for-ui-based-ingestion"},"guide"),"."),(0,a.yg)("h2",{id:"demo"},"Demo"),(0,a.yg)("p",null,"Click ",(0,a.yg)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=EyMyLcaw_74"},"here")," to see a full demo of the UI Ingestion feature."),(0,a.yg)("h2",{id:"feedback--questions--concerns"},"Feedback / Questions / Concerns"),(0,a.yg)("p",null,"We want to hear from you! For any inquiries, including Feedback, Questions, or Concerns, reach out on ",(0,a.yg)("a",{parentName:"p",href:"https://datahubspace.slack.com/join/shared_invite/zt-nx7i0dj7-I3IJYC551vpnvvjIaNRRGw#/shared-invite/email"},"Slack"),"!"))}f.isMDXComponent=!0}}]);